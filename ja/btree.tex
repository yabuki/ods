\chapter{外部メモリの探索}
\chaplabel{btree}
この本を通じて、計算のモデルとしては、\secref{model}で定義した#w#ビットのワードRAMモデルを使ってきた。
このモデルでは、データ構造内のすべてのデータを格納できるくらいコンピュータのRAMが大きいことを暗に仮定している。
この仮定は、場合によっては成り立たない。
大きすぎてコンピュータのメモリには収まりきらないデータもある。
そのような場合は、ハードディスクドライブ（HDD）、ソリッドステートドライブ（SSD）、あるいはネットワーク越しのサーバーなど、外部ストレージにデータを保持するしかない。

\ejindex{external storage}{がいぶすとれーじ@外部ストレージ}%
\ejindex{external memory}{がいぶめもり@外部メモリ}%
\ejindex{hard disk}{はーどでぃすく@ハードディスク}%
\index{solid-state drive}%
外部ストレージへのデータアクセスは非常に遅い。
この本を書くのに使っているコンピュータでは、ハードディスクへの平均アクセス時間は19msである。SSDでも0.3msかかる。
これに対し、RAMへの平均アクセス時間は0.000113ms未満である。
RAMへのアクセスは、SSDと比べて2500倍、HDDと比べると160000倍以上も高速なのである。

%  HDD: Fantom ST3000DM001-9YN166 USB 3 external drive (3TB)
%  SSD: ATA OCZ-AGILITY 3 (60GB)
%  Mem: Mushkin Enhanced Essentials 4GB (2 x 2GB) 204-Pin DDR3 
%       SO-DIMM DDR3 1066 (PC3 8500) Dual Channel Kit Laptop Memory
%       Model 996643
%  RAM speed was estimated using this program:
% #include<stdlib.h>
% #include<stdio.h>
% #include<time.h>
% 
% int main(void) {
%    unsigned *a, x, i, n = 50000000;
%    clock_t start, stop;
% 
%    start = clock();
%    a = malloc(sizeof(unsigned)*n);
%    for(i = 0; i < n; i++) {
%      x |= a[rand()%n];
%    }
%    stop = clock();
%    printf("x=%x, %g\n", x, (((double)(stop-start))/(double)CLOCKS_PER_SEC)/(double)n);
%    free(a);
%    return 0;
% }

RAMのほうが、HDDやSSDよりも、数千倍も高速にランダムアクセスが可能である。
この速度そのものには何も特別なことはない。
問題は、アクセスにかかる時間だけですべてを説明できるわけではないことにある。
HDDやSSD上のバイトにアクセスするとき、実際には、
\emph{ブロック（block）}単位で読み出しを行う。
\ejindex{block}{ぶろっく@ブロック}%
コンピュータに接続されている各ドライブのブロックの大きさは4096である
\footnote{訳注：異なる大きさが使われることもあるが、ここでは簡単のため4096で統一している。}。
つまり、1バイトの読み出しをするたびに、ドライブは4096バイトを返してくる。
このことを踏まえてデータ構造を設計すれば、どのような操作を完了する場合であれ、HDDやSDDから4096バイトのデータを引き出してこられるだろう。

% morin@peewee:~/git/ods/latex$ sudo blockdev --report
% RO    RA   SSZ   BSZ   StartSec            Size   Device
% rw   256   512  4096          0     60022480896   /dev/sda   SSD
% rw   256  4096  4096        504   3000581885952   /dev/sdb1  HDD

これが\emph{外部メモリモデル（external memory model）}の背景となる発想だ。
\ejindex{external memory model}{がいぶめもりもでる@外部メモリモデル}%
\figref{em}に模式図を示す。
このモデルでは、コンピュータはすべてのデータが保存されている大きな外部メモリにアクセスできる。
このメモリは\emph{ブロック}に分割されている。
\ejindex{block}{ぶろっく@ブロック}%
各ブロックは$B$ワードのデータを含む。
コンピュータには、計算を実行できる有限の内部メモリもある。
内部メモリと外部メモリの間でブロックを転送するには一定の時間がかかる。
内部メモリでの計算は\emph{フリー}である。つまり、一切の時間がかからない。
奇妙な仮定に感じるかもしれないが、外部メモリへのアクセスが非常に遅いことを強調しているだけである。

\begin{figure}
  \centering{\includegraphics[width=\ScaleIfNeeded]{figs/em}}
  \caption{外部メモリモデルでは、外部メモリに含まれる要素#x#にアクセスするために、#x#を含むブロックをまるごとRAMに読み込む必要がある}
  \figlabel{em}
\end{figure}

本格的な外部メモリモデルでは、内部メモリの大きさも変数として考慮する必要がある。
しかし、この章で扱うデータ構造では、大きさが$O(B+\log_B #n#)$の内部メモリがあると考えれば十分である。
つまり、定数個のブロックと高さ$O(\log_B #n#)$のスタックを保持できるだけの内部メモリが必要ということである。
必要な内部メモリの大きさを左右するのは、多くの場合、$O(B)$の項である。
例えば、$B$が比較的小さな値$32$であるとしても、すべての$#n#\le 2^{160}$について$B\ge \log_B #n#$が成り立つ。
十進表記で書くと、以下を満たす任意の#n#について$B\ge \log_B #n#$が成り立つ。
\[
#n# \le 1{,}461{,}501{,}637{,}330{,}902{,}918{,}203{,}684{,}832{,}716{,}283{,}019{,}655{,}932{,}542{,}976
\]
% TODO caprice システムコールの脚注
\section{#BlockStore#}
\index{block store}%
\index{BlockStore@#BlockStore#}%
外部メモリにはHDDやSSDなどさまざまなデバイスが含まれる。
ブロックの大きさはデバイスごとに定義されており、それぞれ独自のシステムコールによってアクセスされる。
汎用性がある考え方を伝えるために、この章では解説を単純にしたいので、#BlockStore#というオブジェクトで外部メモリのデバイスを隠蔽することにする。
#BlockStore#には、ブロックの集まりが格納されている。
% caprice 原文は memory block となっているが、他の訳文同様に、単純にブロックと呼んだほうが読みやすいと判断した
各ブロックの大きさは$B$である。
各ブロックは整数のインデックスで一意に識別できる。% YJ インデックスに対応する日本語はあるか？
#BlockStore#がサポートする操作は次のとおり。

\begin{enumerate}
  \item #readBlock(i)#：インデックス#i#で示されるブロックの内容を返す
  \item #writeBlock(i,b)#：インデックス#i#で示されるブロックに#b#の内容を書く
  \item #placeBlock(b)#：新規のインデックスを返し、そのインデックスが示すブロックに#b#の内容を書く
  \item #freeBlock(i)#：インデックス#i#が示すブロックを開放する。これは、指定したブロックの内容をもう使わず、このブロックに割り当てられていた外部メモリを別の用途に使ってよいことを意味する
\end{enumerate}

$B$バイトごとのブロックに分割されたディスク上のファイルが#BlockStore#であると考えるとわかりやすいだろう。
#readBlock(i)#および#writeBlock(i,b)#は、このファイルに対するバイト列$#i#B,\ldots,(#i#+1)B-1$の読み書きに相当する。
さらに、#BlockStore#では、利用可能なブロックからなる\emph{フリーリスト}を保持してもよい。% YJ: Free listに対応するテクニカルタームが存在する？
フリーリストには、#freeBlock(i)#により解放されたブロックを追加する。
そのうえで#placeBlock(b)#ではフリーリストのブロックを使い、もし利用可能なフリーリストがなければファイルの末尾に新しいブロックを追加すればよい。

\section{B木}
\seclabel{btree}

この節では、$B$木と呼ばれる、二分木を一般化したデータ構造について説明する。
$B$木は外部メモリモデルにおける効率的なデータ構造である。
なお、\secref{twofour}で説明した2-4木の自然な一般化として$B$木を考えることもできる
（$B$木において$B=2$とおくと2-4木になる）。

\ejindex{B-tree@$B$-tree}{Bぎ@B木}%
$B\ge 2$を任意の整数とする。
\emph{$B$木}とは、すべての葉が同じ深さにある木であり、すべての根でない内部ノード#u#について、その子の数が$B$以上$2B$以下であるようなものである。
ノード#u#の子は、配列#u.children#に格納される。
根については、子の数に対する条件を緩くして、2以上$2B$以下とする。

% TALK upper bound は ルートが2Bの子を持つとき、つまり (2B)^(h) ではないのか？
% YJ: そうだと思う。根を含むすべての内部ノードが2B個の子を持つと(2B)^(h)になる。
$B$木の高さが$h$のとき、葉の数$\ell$は次の式を満たす。
%\footnote{訳注：左辺は根の子が２個のみで全ての内部ノードがB個の子を持つとき、右辺は葉以外のノードの子が全て2B個であるときの葉の数である。}。
\[
    2B^{h-1} \le \ell \le (2B)^{h}
\]
この式の左辺は、根の子が$2$個のみですべての内部ノードが$B$個の子を持つときの葉の数に対応する。右辺は、葉以外のノードの子がすべて$2B$個であるときの葉の数に対応する。
最初の不等式の両辺から対数を取り、項を並べ替えると、次の式が得られる。
\begin{align*}
    h & \le \frac{\log \ell-1}{\log B} + 1  \\
      & \le \frac{\log \ell}{\log B} + 1 \\
      & = \log_B \ell + 1
\end{align*}
つまり、$B$木の高さは$B$を底とする葉の数の対数に比例する。

$B$木における各ノード#u#には、キーの配列$#u.keys#[0],\ldots,#u.keys#[2B-1]$を格納する。
#u#が$k$個の子を持つ内部ノードのとき、#u#に格納されるキーの数はちょうど$k-1$個であり、それぞれ$#u.keys#[0],\ldots,#u.keys#[k-2]$に格納される。
#u.keys#における残りの$2B-k+1$個の配列のエントリは#null#にしておく。
#u#が根でない葉ノードのとき、#u#は$B-1$個以上$2B-1$個以下のキーを持つ。
$B$木におけるキーは、二分探索木と同様の順序に従う。
$k-1$個のキーを格納する任意のノード#u#は次の式を満たす
%\footnote{訳注：文献によってはキー値の重複を許す場合もあるようだが、\secref{btree-amortized}で後述されるように、この本においては、B木の実装である#BTree#クラス（後述）は#SSet#インターフェースの実装だと説明されている。すなわち、要素の重複はない。}
\footnote{訳注：この本では、B木をキーの重複がない#SSet#インターフェースを実装するために使うので、等号なしの不等号になる。キーの重複があるmultisetの実装時は、$#u.keys[0]# \leq #u.keys[1]# \leq \cdots \leq #u.keys#[k-2]$、$#u.children[i]# \preceq #u.keys[i]# \preceq #u.children[i+1]#$を満たす。}
。
\[
   #u.keys[0]# < #u.keys[1]# < \cdots < #u.keys#[k-2]
\]
% TALK これ、 < でいいのか？ [Cormen 09]だと<=で定義してるのだが % YJ: ここではSetの実装として定義しているためかと。Introduction to Algorithmでも<=で定義されていた。
#u#が内部ノードなら、任意の$#i#\in\{0,\ldots,k-2\}$について、$#u.keys[i]#$は#u.children[i]#を根とする部分木に格納されるどのキーよりも大きく、$#u.children[i+1]#$を根とする部分木に格納されるどのキーよりも小さい。
つまり、厳密な書き方ではないが、次が成り立つ。
\[
   #u.children[i]# \prec #u.keys[i]# \prec #u.children[i+1]#
\]
$B=2$である$B$の例を\figref{btree}に示す。

\begin{figure}
  \centering{\includegraphics[width=\ScaleIfNeeded]{figs/btree-1}}
  \caption{$B=2$である$B$木}
  \figlabel{btree}
\end{figure}

$B$木のノードに格納されるデータの大きさは$O(B)$である。
そのため、外部メモリとして使うことを考えると、$B$木の$B$の値は外部メモリのブロックの大きさに合わせて選ぶことになる。
そうすれば、外部メモリモデルにおいて$B$木の操作にかかる時間は、操作時にアクセス（読み書き）するノードの数に比例する。

例えば、キーが4バイト整数であり、ノードのインデックスも4バイトであるとする。
このとき、$B=256$とすれば、各ノードは次式により4096バイトのデータを格納することになる。
\[
(4+4)\times 2B
 = 8\times512=4096
\]
この章の冒頭で説明したように、ハードディスクやSSDのブロックサイズは$4096$バイトなので、この$B$はこれらのデバイスに適した値である。

% caprice インデックスを添え字と訳すこともできるが、riやuiのようにiが変数名の末尾に使われているので、単にカタカナにしたほうがその点が読みやすいと判断した
#BTree#クラスは、$B$木の実装である。
#BTree#クラスには、#BlockStore#オブジェクト#bs#を格納する。
この#bs#に、根のインデックス#ri#と、#BTree#のノードを格納する。
他のデータ構造の場合と同様に、整数#n#はデータ構造の要素数を表す。
\cppimport{ods/BTree.n.ri.bs}
\javaimport{ods/BTree.n.ri.bs}
\pcodeimport{ods/BTree.initialize(b)}

\subsection{要素の探索}

#find(x)#の実装（\figref{btree-find}に示したもの）は、二分探索木における#find(x)#操作の一般化である。
#x#の探索を根から開始し、ノード#u#のキーを利用して、#u#の子のうちのどちらに探索を進めるべきかを決める。

\begin{figure}
  \centering{\includegraphics[width=\ScaleIfNeeded]{figs/btree-2}}
  \caption{$B$木における成功する探索（4を探す）と、失敗する探索（16.5を探す）の様子。色を付けたノードは探索の途中に値が更新されるものである}
  \figlabel{btree-find}
\end{figure}
具体的には、ノード#u#において、探索している#x#が#u.keys#に格納されているかどうかを確認する。
格納されていれば、#x#が見つかったので処理を終了する。
格納されていなければ、$#u.keys[i]# > #x#$を満たす最小の整数#i#を求め、#u.children[i]#を根とする部分木に進んで探索を続ける。
#u.keys#に#x#より大きなキーがないときは、#u#の一番右の子に進んで探索を続ける。
二分探索木の場合と同様に、このアルゴリズムでは、#x#より大きなキーのうち最後に訪れたもの#z#を記録しておく。
#x#が見つからなかったときは、#x#以上の最小の値である#z#を返す。
\codeimport{ods/BTree.find(x)}
#find(x)#の肝は、#null#で埋められた配列#a#から#x#を探す、#findIt(a,x)#というメソッドである。
\figref{findit}に示したように、$#a#[0],\ldots,#a#[k-1]$はキーが整列された状態であり、$#a#[k],\ldots,#a#[#a.length#-1]$にはすべて#null#が入っている。
#x#がこの配列の#i#番めの位置に入っているとき、#findIt(a,x)#は$-#i#-1$を返す。% TODO: YJ 場合分けのために負の値にするというのは低レベルの実装の都合に寄りすぎた説明で好きではない
そうでないときは、$#a[i]#>#x#$または$#a[i]#=#null#$を満たす最小のインデックス#i#を返す。
\begin{figure}
  \centering{\includegraphics[scale=0.90909]{figs/findit}}
  \caption{#findIt(a,27)#を実行する様子}
  \figlabel{findit}
\end{figure}
\codeimport{ods/BTree.findIt(a,x)}
#findIt(a,x)#では二分探索を使う。
\ejindex{binary search}{にぶんたんさく@二分探索}%
各ステップで探索空間が半分ずつ減っていくので、$O(\log(#a.length#))$の時間で処理が完了する。
この実装では$#a.length#=2B$なので、#findIt(a,x)#の（RAMモデルでの）実行時間は$O(\log B)$である。

$B$木における#find(x)#の実行時間は、ワードRAMモデル（全命令を数える）でも、外部メモリモデル（アクセスするノードの数だけを数える）でも解析できる。
$B$木の葉には、少なくとも1つのキーが格納されており、$\ell$個の葉を持つ$B$木の高さは$O(\log_B\ell)$なので、#n#個のキーを格納する$B$木の高さは$O(\log_B #n#)$である。
よって、外部メモリモデルにおける#find(x)#の実行時間は$O(\log_B #n#)$である。
ワードRAMモデルにおける実行時間を計算するためには、アクセスするすべてのノードについて、#findIt(a,x)#呼び出しのコストを考えればよい。
したがって、この場合の#find(x)#の実行時間は次のようになる。
\[
   O(\log_B #n#)\times O(\log B) = O(\log #n#)
\]

\subsection{要素の追加}
\seclabel{btree-elem-add}

$B$木と、\secref{binarysearchtree}で説明した#BinarySearchTree#との重要な違いは、$B$木のノードには親へのポインタがないことである。
なぜ$B$木で親へのポインタを保持していないかは、あとで軽く説明する。
親へのポインタがないことから、$B$木における#add(x)#と#remove(x)#は再帰を使って実装するのが最も簡単である。

他のバランスされた探索木と同様に、#add(x)#では何らかのバランス調整が必要になる。
$B$木では、ノードの\emph{分割}によってバランスを調整する。
\ejindex{split}{ぶんかつ@分割}%
以降の説明は\figref{btree-split}を見ながら読んでほしい\footnote{訳注： \figref{btree-split}の\cent{}記号は、後の節で実行時間の解析に使うものなので、ここでは無視してよい。}。% 訳注はやや冗長か？
分割は二段階の再帰におよぶのだが、$2B$個のキーを含んで$2B+1$個の子を持つノード#u#を引数とする操作であると考えると理解しやすいだろう。
新たなノード#w#を作り、このノードに$#u.children#[B],\ldots,#u.children#[2B]$を引き受けさせる。
新たなノード#w#には、#u#のキーのうち、大きいほうから$B$個（$#u.keys#[B],\ldots,#u.keys#[2B-1]$）も持たせる。
この時点で、#u#は、$B$個の子と$B$個のキーを持っている。
余分なキーである$#u.keys#[B-1]$は、#u#の親に渡す。#u#の親には、#w#も子として引き受けさせる。

分割で操作するノードは3つあることに注目してほしい。
具体的には、#u#、#u#の親、新たなノード#w#を操作する。
$B$木で親へのポインタを持たないことが重要なのは、これが理由である。
もし親へのポインタがあれば、#w#が引き取る$B+1$個の子すべてについて、親へのポインタを#w#へのポインタとして書き換える必要がある。
これによって外部メモリへのアクセスが3回から$B+4$回に増えるので、$B$が大きいときに$B$木が非効率になってしまう。

\begin{figure}
   \centering{\begin{tabular}{@{}l@{}}
     \includegraphics[width=\ScaleIfNeeded]{figs/btree-split-1} \\[2ex]
     \multicolumn{1}{c}{#u.split()#} \\ 
     \multicolumn{1}{c}{$\Downarrow$} \\[2ex]
     \includegraphics[width=\ScaleIfNeeded]{figs/btree-split-2} \\
   \end{tabular}}
   \caption{$B=3$である$B$木における、ノード#u#の分割。キー$#u.keys#[2]=\mathrm{m}$は#u#からその親に移る}
   \figlabel{btree-split}
\end{figure}

$B$木における#add(x)#の様子を\figref{btree-add}に示す。
俯瞰的に捉えると、#add(x)#メソッドによって、値#x#を追加すべき葉#u#が見つかる。
追加によって#u#が一杯になる（つまり、すでに#u#に$2B-1$個のキーがある）場合には、#u#を分割する。
それによって#u#の親が一杯になる場合には、#u#の親を分割する。
それによって#u#の親の親が一杯になる場合には、#u#の親の親を分割する……という操作を繰り返す。
木を1つずつ上に登りながら、一杯でないノードを見つけるか、根を分割することになるまで、この操作を繰り返す。
一杯でないノードが見つかった場合には、単に操作を終了する。
根を分割することになる場合には、新たな根を作り、元の根を分割して得られる2つのノードを両方とも新しい根の子にする
\footnote{訳注：これに似た議論は\secref{redblack-add-by-divide}に出てくる。}。

\begin{figure}
   \centering{\begin{tabular}{@{}l@{}}
     \includegraphics[width=\ScaleIfNeeded]{figs/btree-add-1} \\[2ex]
     \multicolumn{1}{c}{$\Downarrow$} \\[2ex]
     \includegraphics[width=\ScaleIfNeeded]{figs/btree-add-2} \\[2ex]
     \multicolumn{1}{c}{$\Downarrow$} \\[2ex]
     \includegraphics[width=\ScaleIfNeeded]{figs/btree-add-3}
   \end{tabular}}
   \caption{#BTree#における#add(x)#の様子。値21を追加すると、2つのノードが分割される}
   \figlabel{btree-add}
\end{figure}

#add(x)#メソッドが実行することを整理すると、次のようになる。
すなわち、#x#を追加すべき葉を探して根から開始し、見つけた葉に#x#を追加して、それから根に向かって戻り、その途中で一杯になったノードを見かけたらすべて分割する。
おおまかな動作がわかったところで、再帰的な実装方法を見ていこう。

#add(x)#で処理のほとんどを担当する
#addRecursive(x,ui)#は、識別子#ui#を持つノード#u#を根とする部分木に#x#を追加するメソッドだ。
#u#が葉なら、単に#x#を#u.keys#に挿入する。
そうでないときは、#u#の子のうちで適切なもの$#u#'$に対し、#x#を再帰的に処理する。
この再帰的な呼び出しは、通常は#null#を返すが、$#u#'$が分割された場合は、新たに作られるノード#w#の参照を返すことがある。
後者の場合には、#u#が#w#を子として最初のキーを引き取り、$#u#'$の分割処理を終える。

#addRecursive(x,ui)#では、#u#または#u#の子孫に#x#を追加したあと、#u#の持つキーが多すぎないか（$2B-1$より多くないか）どうかを確認する。
もし多すぎるなら、#u#を\emph{分割}しなければならないので、#u.split()#を呼ぶ。
#u.split()#の返り値である新しいノードが、#addRecursive(x,ui)#の返り値として使われる。
\codeimport{ods/BTree.addRecursive(x,ui)}

#addRecursive(x,ui)#は#add(x)#の下請けである。#add(x)#では、#x#を$B$木の根に挿入するために、#addRecursive(x,ri)#を呼ぶ
\footnote{訳注：整数#ri#は、#BTree#クラスで根のインデックスとして定義したことを思い出そう。一方で、#addRecursive(x,ui)#の引数として用いられている#ui#は、最初の呼び出しでは#ri#そのものであるが、以降はノード#u#のインデックスであることに注意。}。
#addRecursive(x,ri)#によって根が分割される場合、新しい根は、古い根および古い根の分割において新たに作られたノードを子として持つ。
\codeimport{ods/BTree.add(x)}

#add(x)#および#addRecursive(x,ui)#は、二段階に分けて解析できる。

\begin{description}
  \item[下向きに進む段階]
  再帰において下向きに進む段階では、#x#を追加する前に、各ノードにて#findIt(a,x)#を呼び、#BTree#のノードを順番にアクセスする。
  #find(x)#と同様に、このメソッドの実行時間は、外部メモリモデルでは$O(\log_B #n#)$、ワードRAMモデルでは$O(\log #n#)$である。

  \item[上向きに進む段階]
  再帰において上向きに進む段階では、#x#を追加したあと、合計で最大$O(\log_B #n#)$回の分割を行う。
  各分割は3つのノードだけに影響するので、この段階の実行時間は、外部メモリモデルでは$O(\log_B #n#)$である。
  しかし、各分割では$B$個のキーと子をノードからノードに移すので、ワードRAMモデルでは$O(B\log #n#)$である。
  \end{description}

$B$の値はかなり大きくなる。$\log #n#$と比べてもだいぶ大きいことを思い出そう。
そのため、ワードRAMモデルでは、$B$木への要素の追加はバランスされた二分探索木への追加よりもかなり遅くなる可能性がある。
このあと、\secref{btree-amortized}で、状況がそれほど悲惨ではないことを示す。
実は、償却すると、#add(x)#で実行される分割の回数は定数オーダーなのである。
したがって、ワードRAMモデルにおける#add(x)#の償却実行時間は、$O(B+\log #n#)$である。

\subsection{ノードの削除}
#BTree#における#remove(x)#も、実装には再帰を使うのが最も簡単だ。
再帰による#remove(x)#の実装は、いくつかのメソッドにまたがる複雑なものだが、\figref{btree-remove-full}に示したように全体として見ればとても素直である。
削除という課題は、うまくキーを入れ替えることで、ある葉#u#から値$#x#'$を削除するという問題に帰結される。
$#x#'$を削除することで、#u#の持つキーの数が$B-1$未満になる場合もあるだろう。
この状態を\emph{アンダーフロー（underflow）}と呼ぶことにする。
\ejindex{underflow}{あんだーふろー@アンダーフロー}%

\begin{figure}
   \centering{\begin{tabular}{@{}l@{}}
     \includegraphics[width=\ScaleIfNeeded]{figs/btree-remove-full-1} \\[2ex]
     \multicolumn{1}{c}{$\Downarrow$} \\[2ex]
     \includegraphics[width=\ScaleIfNeeded]{figs/btree-remove-full-2} \\[2ex]
     \multicolumn{1}{c}{#merge(v,w)#} \\
     \multicolumn{1}{c}{$\Downarrow$} \\[2ex]
     \includegraphics[width=\ScaleIfNeeded]{figs/btree-remove-full-3} \\[2ex]
     \multicolumn{1}{c}{#shiftLR(w,v)#} \\
     \multicolumn{1}{c}{$\Downarrow$} \\[2ex]
     \includegraphics[width=\ScaleIfNeeded]{figs/btree-remove-full-4} \\[2ex]
   \end{tabular}}
   \caption{この$B$木から値4を削除すると、併合と借用が1回ずつ発生する}
   \figlabel{btree-remove-full}
\end{figure}

アンダーフローが発生した場合、#u#は、自分の兄弟からキーを借用するか、自分の兄弟のいずれかと併合することになる。
兄弟と併合する場合は、#u#の親が持つ子とキーの数が1ずつ減り、結果として今度は#u#の親でアンダーフローが発生するかもしれない。
このアンダーフローは、再び兄弟からのキーの借用か、兄弟との併合により解決される。併合すれば、今度は#u#の親の親でアンダーフローが発生するかもしれない。
この処理は根へと上向きに進み、アンダーフローが発生しなくなるか、根の2つの子が1つに併合されるかすれば終了する。
後者の場合は根が削除され、その唯一の子が新たな根になる。

それでは、各ステップの実装方法を詳細に見ていこう。
#remove(x)#で最初にすべきことは、削除する要素#x#の探索である。
#x#が葉で見つかったなら、その葉から#x#を削除する。
そうでなく、#x#がある内部ノード#u#の#u.keys[i]#で見つかったなら、#u.children[i+1]#を根とする部分木の最小値#x'#を削除する。
#x'#は、#x#より大きい値を格納する#BTree#の最小値である。
続いて、#x'#の値で#u.keys[i]#の#x#を置き換える。
\figref{btree-remove}にこの処理の様子を示す。

\begin{figure}
   \centering{\begin{tabular}{@{}l@{}}
     \includegraphics[width=\ScaleIfNeeded]{figs/btree-remove-1} \\[2ex]
     \multicolumn{1}{c}{$\Downarrow$} \\[2ex]
     \includegraphics[width=\ScaleIfNeeded]{figs/btree-remove-2}
   \end{tabular}}
   \caption{#BTree#において#remove(x)#を実行する様子。値$#x#=10$を削除するとき、その値を$#x'#=11$で上書きし、値11を含む葉を削除する}
   \figlabel{btree-remove}
\end{figure}

#removeRecursive(x,ui)#は、上記で説明したアルゴリズムの再帰的な実装である。
\codeimport{ods/BTree.removeRecursive(x,ui).removeSmallest(ui)}

#removeRecursive(x,ui)#では、#u#の#i#番めの子から値#x#を再帰的に削除したあと、この子が少なくとも$B-1$個のキーを持っていることを保証しなければならない。
上記のコードでは、#checkUnderflow(x,i)#がこの処理を行っている。
このメソッドは、#u#の#i#番めの子についてアンダーフローの発生を確認し、修正する。
#w#を#u#の#i#番めの子とする。
#w#のキーが$B-2$個しかないなら、修正の必要がある。
これには#w#の兄弟を利用する。
#u#の$#i#+1$番め、または$#i#-1$番めの子を使う。
通常は#u#の$#i#-1$番めの子#v#、つまり#w#のすぐ左の兄弟を使う。
$#i#=0$のときだけはこれがうまくいかないので、#w#のすぐ右の兄弟を使う。
\codeimport{ods/BTree.checkUnderflow(u,i)}
ここでは$#i#\neq 0$の場合のみを考え、#u#の#i#番めの子で発生したアンダーフローが#u#の$(#i#-1)$番めの子の助けを借りて修正できることを確認する。
$#i#=0$の場合も同様に処理できるので、詳細はソースコードを参照してほしい。

#w#におけるアンダーフローを解決するには、#w#に追加するキー（場合によっては子も）を見つけてくる必要がある。
そのための操作は2種類ある。

\begin{description}
  \item[借用]
  \ejindex{borrow}{しゃくよう@借用}%
  #w#の兄弟#v#が持っているキーの個数が$B-1$より多ければ、#w#は#v#からキー（場合によっては子も）を借りられる。
  具体的には、#v#のキーの個数が#size(v)#なら、#v#と#w#とが持っているキーの個数の合計は次のようになる。
  \[
     B-2 + #size(v)# \ge 2B-2
  \]
  よって、#v#から#w#にキーを移し、#v#と#w#のいずれもが$B-1$個以上のキーを持つ状態にできる。
  この操作の様子を\figref{btree-borrow}に示す。

  \begin{figure}
      \centering{\begin{tabular}{@{}l@{}}
       \includegraphics[width=\ScaleIfNeeded]{figs/btree-borrow-1} \\[2ex]
       \multicolumn{1}{c}{#shiftRL(v,w)#} \\ 
       \multicolumn{1}{c}{$\Downarrow$} \\[2ex]
       \includegraphics[width=\ScaleIfNeeded]{figs/btree-borrow-2} \\
     \end{tabular}}
    \caption{#v#のキーの個数が$B-1$個より多いとき、#w#は#v#からキーを借りられる}
    \figlabel{btree-borrow}
  \end{figure}

  \item[併合]
  \ejindex{merge}{へいごう@併合}%
  #v#のキーの個数が$B-1$個だけしかないとき、#v#にはキーを渡す余裕がないので、もっと思い切った操作が必要になる。
  それは、\figref{btree-merge}に示すように、#v#と#w#の\emph{併合}である。
  併合は分割とは逆の操作である。
  合計で$2B-3$個のキーを持つ2つのノードを併合し、$2B-2$個のキーを持つ1つのノードにする
  （併合されたノードでキーの個数が1つ増えるのは、#v#と#w#を併合すると両者の親#u#の子の数が1つ減るので、#u#が保有するキーの1つを併合されたノードに受け渡す必要があるからである）。

  \begin{figure}
     \centering{\begin{tabular}{@{}l@{}}
       \includegraphics[width=\ScaleIfNeeded]{figs/btree-merge-1} \\[2ex]
       \multicolumn{1}{c}{#merge(v,w)#} \\ 
       \multicolumn{1}{c}{$\Downarrow$} \\[2ex]
       \includegraphics[width=\ScaleIfNeeded]{figs/btree-merge-2} \\
     \end{tabular}}
     \caption{$B=3$である$B$木の兄弟#v#と#w#を併合する}
     \figlabel{btree-merge}
  \end{figure}
\end{description}

\codeimport{ods/BTree.checkUnderflowNonZero(u,i).checkUnderflowZero(u,i)}

まとめると、$B$木における#remove(x)#では、根から葉まである経路を辿り、#x'#を葉#u#から削除して、そのあとで0回以上の併合を#u#とその祖先に対して実行し、高々1回の借用をする。
併合や借用では3つのノードしか修正せず、操作の回数は$O(\log_B #n#)$なので、外部メモリモデルにおける#remove(x)#の全体としての実行時間は$O(\log_B #n#)$である。
ただし、ワードRAMモデルでは併合やノードの借用に$O(B)$だけの時間がかかるので、#remove(x)#の実行時間は$O(B\log_B #n#)$である（それ以上のことは現時点ではわからない）。

\subsection{$B$木の償却解析}
\seclabel{btree-amortized}

ここまでに、次の事実を見てきた。
\begin{enumerate}
  \item 外部メモリモデルでは、$B$木における#find(x)#、#add(x)#、#remove(x)#の実行時間はそれぞれ$O(\log_B #n#)$である
  \item ワードRAMモデルでは、#find(x)#の実行時間は$O(\log #n#)$であり、#add(x)#および#remove(x)#の実行時間は$O(B\log #n#)$である
\end{enumerate}

次の補題により、$B$木における分割および併合操作の回数に関するこれまでの見積もりが過剰であったことがわかる。

\begin{lem}\lemlabel{btree-split}
空の$B$木から始めて、#add(x)#および#remove(x)#からなる$m$個の操作の列を順に実行するとき、分割、併合、借用は合わせて高々$3m/2$回しか実行されない。
\end{lem}

\begin{proof}
   $B=2$という特別な場合については、すでに\secref{redblack-summary}で証明の概要を示した。
   % Scapegoat木はクレジット -> 預金と訳している。とりあえず一貫性を保つため預金にした。
   この補題を証明するには、次のような性質のもとで出納法を使えばよい。
   \ejindex{credit scheme}{すいとうほう@出納法}%
  \begin{enumerate}
    \item 分割、併合、借用の際に、預金2を支払う（失う）
    \item #add(x)#または#remove(x)#の際には、最大で預金3が得られる
  \end{enumerate}
  最大で得られる預金が$3m$であり、分割、併合、借用されるたびに支払う預金が2なので、最大で$3m/2$回の分割、併合、借用が実行されることになる。
  \figref{btree-split}、\figref{btree-borrow}、\figref{btree-merge}では、預金を\cent{}で表した。

  証明では、預金の値を追うために、次の\emph{預金不変条件（credit invariant）}を考える。% 箇条書きにしました -kshikano
  \ejindex{credit invariant}{くれじっとふへんじょうけん@預金不変条件}%
  \begin{itemize}
  \item $B-1$個のキーを持つ任意の根でないノードは預金を1だけ持つ
  \item $2B-1$個のキーを持つノードは預金を3だけ持つ
  \item $B$以上$2B-2$以下のキーを持つノードは預金を持たない
  \end{itemize}
  そのうえで、毎回の#add(x)#および#remove(x)#の操作で預金不変条件を保持できること、証明の冒頭で提示した性質1と2を満たせることを示せばよい。

  \paragraph{追加の場合}
  #add(x)#では併合や借用が発生しないので、分割だけを考えれば十分である。

  すでに$2B-1$個のキーを持つノード#u#にキーを追加すると、分割が発生する。
  この場合、#u#は2つのノード#u'#と#u''#に分割され、それぞれは$B-1$個および$B$個のキーを持つ。
  直前には#u#が$2B-1$個のキーを持っていたので、預金は3あった。
  そのうちの2は分割のために支払われ、残りの1は$B-1$個のキーを持つ#u'#に渡されるので、預金不変条件は保持される。
  よって、いかなる分割においても、預金不変条件を保ちながら、その分割のための預金を支払える。

  それ以外に、#add(x)#の実行中にノードに対して発生する操作は、分割が起こるとして、それらの分割がすべて終わったあとで実行される。
  発生する操作は、新たなキーをあるノード#u'#に追加する処理に関係するものだ。
  それ以前に#u'#の子の数が$2B-2$個だったならば、子の数が$2B-1$になるので、#u'#は預金3を得ることになる。
  #add(x)#メソッドによって放出される預金はこれだけである。

  \paragraph{削除の場合}
  #remove(x)#の際には、0回以上の併合と、それに続く借用が1回発生する可能性がある。
  併合が発生するのは、#remove(x)#を呼ぶ前に2つのノード#v#と#w#が共に$B-1$個のキーを持っていて、この2つのノードが$2B-2$個のキーを持つ1つのノードに併合されるという状況である。
  そのため、併合のたびに、併合に使われる預金2が支払われている。

  併合のあとには、借用が高々1回発生する。それ以降は、併合も借用も発生しない。
  借用が起こるのは、$B-1$個のキーを持つ葉#v#からキーを削除する場合に限られる。
  このとき#v#は預金1を持っており、この預金が借用のコストとして使われる。
  しかし、借用のコストは2なので、預金が1足らない。支払いを完了するには、預金があと1必要である。

  この時点で作り出した預金が1あるので、預金不変条件が保持されていることを示す必要がある。
  最悪の場合、#v#の兄弟#w#が借用の前にちょうど$B$個のキーを持っていて、直後には#v#と#w#が両方とも$B-1$個のキーを持つことになる。
  これは、操作が完了するとき、#v#と#w#が預金を1持っている必要があることを意味する。
  この場合には、#v#と#w#に渡すために、追加で2の預金を作る必要がある。
  借用は#remove(x)#の処理において高々1回発生するので、必要に応じて最大で3の預金を作ることになる。

  #remove(x)#において借用が発生しないのは、操作の前に$B$個以上のキーを持っていたノードからキーを削除して終了した場合である。
  最悪の場合、キーを削除されたノードは操作の前にちょうど$B$個のキーを持っていて、そのため操作後のキーの個数が$B-1$になっているので、作った預金から1を与えなければならない。

  削除が借用で終わるにせよ、そうでないにせよ、預金不変条件を保持して併合と借用のコストを支払うためには、#remove(x)#の呼び出しに際して高々3の預金を作る必要がある。
  以上より補題が示された。
\end{proof}

\lemref{btree-split}の目的は、ワードRAMモデルにおいて#add(x)#および#remove(x)#からなる$m$個の操作の列を順に実行するとき、分割、併合、借用にかかる時間が合わせて$O(Bm)$であることを示すことにあった。
つまり、これらの操作の償却コストは$O(B)$であり、ワードRAMモデルにおける#add(x)#および#remove(x)#の償却コストは$O(B+\log #n#)$である。
この結果を次の2つの定理にまとめる。

\begin{thm}[外部メモリモデルにおける$B$木]
#BTree#は#SSet#インターフェースを実装する。
#BTree#は#add(x)#、#remove(x)#、#find(x)#をサポートし、外部メモリモデルではいずれの実行時間も$O(\log_B #n#)$である。
\end{thm}

\begin{thm}[ワードRAMモデルにおける$B$木]
#BTree#は#SSet#インターフェースを実装する。
#BTree#は#add(x)#、#remove(x)#、#find(x)#をサポートする。ワードRAMモデルでは、分割、併合、借用のコストを無視すると、いずれの実行時間も$O(\log_B #n#)$である。
さらに、空の#BTree#に対して#add(x)#および#remove(x)#からなる$m$個の操作の列を順に実行するとき、分割、併合、借用のためにかかる時間は合わせて$O(Bm)$である。
\end{thm}

\section{ディスカッションと練習問題}

外部メモリモデルを提案したのはAggarwalとVitterである\cite{av88}。
このモデルは\emph{I/Oモデル}
\ejindex{I/O model}{I/Oモデル}%
や\emph{ディスクアクセスモデル}と呼ばれることもある。
\ejindex{disk access model}{でぃすくあくせすもでる@ディスクアクセスモデル}%

$B$木は、内部メモリを使った探索における二分探索木を、外部メモリの場合に拡張したものである。
$B$木は、McCreightが1970年に提案した\cite{bm70}。
それから10年を待たずして、Comerによるサーベイ（論文のタイトルは``The Ubiquitous B-Tree''）が出版され、その中で$B$木は「このデータ構造はいたるところで使われている」と紹介された\cite{c79}。

二分探索木と同様に、$B$木には多くの種類がある。
例えば、$B^+$木、
\ejindex{B+-tree@$B^+$-tree}{B+ぎ@$B^+$木}%
$B^*$木、
\ejindex{B*-tree@$B^*$-tree}{B*ぎ@$B^*$木}%
counted $B$木などである。
\index{counted $B$-tree}%
$B$木は、多くのファイルシステムにおける基本的なデータ構造として、本当にいたるところで使われている。
例えば、
AppleのHFS+、
\index{HFS+}%
MicrosoftのNTFS、
\index{NTFS}%
LinuxのExt4などがある。
\index{Ext4}%
すべてのメジャーなデータベースシステムも$B$木の例である。
クラウドコンピューティングで使われているキーバリューストアにも利用例がある。
Graefeによる近年のサーベイ\cite{g10}では、200ページ以上にわたって、$B$木の現代における応用やデータ構造の変種、最適化などが述べられている。

$B$木は#SSet#インターフェースを実装する。
#USet#インターフェースだけが必要なら、$B$木の代わりに外部メモリハッシュ法を使うこともできるだろう。
\ejindex{external memory hashing}{がいぶめもりはっしゅほう@外部メモリハッシュ法}%
外部メモリハッシュ法も広く研究されている。
例えばJensenとPaghの論文\cite{jp08}を見てほしい。
外部メモリハッシュ法では、$O(1)$の期待実行時間で、外部メモリモデルにおいて#USet#の操作を実行できる。
しかし、いくつかの理由から、多くのアプリケーションでは#USet#の操作だけが必要だとしても$B$木を使っている。

$B$木がよく利用される理由のひとつに、$O(\log_B #n#)$という実行時間の上界から受ける印象よりも実際の性能がよい場合が少なくないという点が挙げられる。
外部メモリモデルでは、$B$の値はふつうかなり大きく、数百あるいは数千である。
そのため、$B$木におけるデータのうち99\%、あるいは99.9\%は葉に保存されている。
大きなメモリを持つデータベースシステムでは、内部ノードはすべてのデータのうちの1\%、あるいは0.1\%程度なので、すべてRAMにキャッシュできるかもしれない。
この場合、$B$木の検索ではRAM上にある内部ノードをすべて非常に高速に処理でき、外部メモリに1回だけアクセスして葉が得られる。

\begin{exc}
  \figref{btree}の$B$木に1.5、7.5を順に追加するときの様子を描け。
\end{exc}

\begin{exc}
  \figref{btree}の$B$木から3、4を順に削除するときの様子を描け。
\end{exc}

\begin{exc}
#n#個のキーを格納する$B$木の内部ノードの数の最大値を求めよ。（これは#n#と$B$の関数である。）
\end{exc}

\begin{exc}
この章の冒頭で、$B$木の内部メモリとして必要なのは$O(B+\log_B#n#)$だけであると述べた。
しかし、この章で示した実装では、実はより多くのメモリが必要である。
  \begin{enumerate}
    \item この章で示した#add(x)#および#remove(x)#の実装では、$B\log_B #n#$に比例する内部メモリを使うことを示せ。
    \item これを$O(B + \log_B #n#)$に減らすための修正方法を説明せよ。
  \end{enumerate}
\end{exc}

\begin{exc}
  \lemref{btree-split}の証明で使った預金の様子を、\figref{btree-add}と\figref{btree-remove-full}の木に描け。
  また、追加の預金3で分割、併合、借用のコストを支払い、預金不変条件を保持できることを確認せよ。
\end{exc}

\begin{exc}
$B$木を修正し、ノードの子の数が$B$以上$3B$以下（したがってキーの数は$B-1$以上$3B-1$以下）のデータ構造を設計せよ。
また、この新しい$B$木では、$m$回の操作を順に実行する際に$O(m/B)$回だけ分割、併合、借用を実行することを示せ。
（ヒント：これを実現するには、場合によっては併合が必要になる前に2つのノードを併合して、より積極的に併合処理を実施する必要があるだろう。）
\end{exc}

\begin{exc}
この練習問題では、$B$木の分割と併合を修正して最大で3つのノードを一度に考慮することで、分割、借用、併合処理の漸近的な実行回数を減らす。
  \begin{enumerate}
    \item 一杯になったノードを#u#とし、#u#のすぐ右の兄弟を#v#とする。
	#u#のノードが溢れるのを解消する方法は2通りある。
    \begin{enumerate}
       \item #u#のキーをいくつか#v#に渡す
       \item #u#を分割し、#u#と#v#のキーを平等に#u#と#v#、それに新しいノード#w#で分け合う
    \end{enumerate}
	この操作のあと、ある定数$\alpha > 0$について、関連する（最大3つの）ノードはいずれも$B+\alpha B$個以上$2B-\alpha B$個以下のキーを持つようにできることを示せ
    \item ノード#u#はアンダーフローしているものとし、#v#および#w#を#u#の兄弟とする。
	#u#のアンダーフローを解消する方法は2通りある。
    \begin{enumerate}
       \item #u#、#v#、#w#の間でキーを分配し直す
       \item #u#、#v#、#w#を併合して2つのノードにする。それぞれが持っていたキーを2つのノードに分配し直す
    \end{enumerate}
	この操作のあと、ある定数$\alpha > 0$について、関連する（最大3つの）ノードはいずれも$B+\alpha B$個以上$2B-\alpha B$個以下のキーを持つようにできることを示せ
    \item 以上の修正によって、$m$回の操作を実行する間に発生する併合、借用、分割の回数が$O(m/B)$になることを示せ。
  \end{enumerate}
\end{exc}


\begin{exc}
  \figref{bplustree}に示した$B^+$木では、すべてのキーを葉に格納し、すべての葉を双方向連結リストとして格納する。
  これまで通り、葉にはそれぞれ$B-1$個以上$2B-1$個以下のキーを格納する。
  葉よりも上側の部分は通常の$B$木であり、その内部ノードには、葉のリストのうち末尾を除いた最大の値が格納されている。
  \begin{enumerate}
    \item $B^+$木における#add(x)#、#remove(x)#、#find(x)#の高速な実装を説明せよ。
    \item #findRange(x,y)#の効率的な実装方法を説明せよ。
	これは、$B^+$木に含まれる#x#より大きく#y#より小さい値をすべて報告するメソッドである。
    \item #find(x)#、#add(x)#、#remove(x)#、#findRange(x,y)#を持つクラス#BPlusTree#を実装せよ。
      \index{BPlusTree@#BPlusTree#}%
    \item $B^+$木では、$B$木の部分とリストの部分の両方に同じキーを格納するため、キーの重複がある。
	$B$の値が大きいとき、この重複が深刻な問題にならない理由を説明せよ。
  \end{enumerate}
\end{exc}

\begin{figure}
  \centering{\includegraphics[width=\ScaleIfNeeded]{figs/bplustree}}
  \caption{$B^+$木は、双方向連結リストの上に$B$木が乗ったデータ構造である}
  \figlabel{bplustree}
\end{figure}
